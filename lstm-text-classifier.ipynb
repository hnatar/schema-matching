{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Text Classifier",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/hnatar/ca03aca0175ca763811c1e73a9ccd8d8/lstm-text-classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QgUkrWTbbALD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Data had e-mails so I've removed the files. Please contact Bo\n",
        "# if you want the original notebook with outputs.\n",
        "class1 = 'foo.txt' # Entries from one field, newline delimited\n",
        "class2 = 'bar.txt' # Entries from other field, newline delimited\n",
        "\n",
        "\"\"\"\n",
        "Training took a while on Colab, so limited to 30.\n",
        "\"\"\"\n",
        "def load_from_file(src):\n",
        "    i = 0\n",
        "    samples = []\n",
        "    with open(f'{src}', 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.strip()\n",
        "            samples.append( line )\n",
        "            i += 1\n",
        "            if i == 30:\n",
        "                break\n",
        "    return samples\n",
        "\n",
        "\"\"\"\n",
        "Samples is a dictionary holding the input\n",
        "samples for that field/class. There are two classes, 1 and 2.\n",
        "\"\"\"\n",
        "samples = {}\n",
        "samples[1] = load_from_file(class1)\n",
        "samples[2] = load_from_file(class2)\n",
        "\n",
        "\"\"\"\n",
        "Please refactor this out.\n",
        "\"\"\"\n",
        "def text2ascii_onehot(s):\n",
        "    \"\"\" returns a (n x 255) tensor where n is len(s),\n",
        "        containing one-hot ascii encoding for s\n",
        "    \"\"\"\n",
        "    x = []\n",
        "    for c in s:\n",
        "        row = [0]*256\n",
        "        row[ord(c)] = 1\n",
        "        x.append( np.array(row) )\n",
        "    return np.array(x)\n",
        "\n",
        "\"\"\"\n",
        "Generates a  sample, ie. if the two inputs are similar/from the\n",
        "same class: pick a class randomly, and pick two random samples\n",
        "from that class. Also returns the ground truth labelling.\n",
        "\"\"\"\n",
        "def generate_valid():\n",
        "    r = np.random.randint(1, 3)\n",
        "    textSample1 = samples[r][ np.random.randint(0, len(samples[r])) ]\n",
        "    textSample2 = samples[r][ np.random.randint(0, len(samples[r])) ]\n",
        "    x1 = text2ascii_onehot(textSample1)\n",
        "    x2 = text2ascii_onehot(textSample2)\n",
        "    return x1, x2, np.array([0, 1]), (textSample1, textSample2,)\n",
        "\n",
        "def generate_invalid():\n",
        "    textSample1 = samples[1][ np.random.randint(0, len(samples[1])) ]\n",
        "    textSample2 = samples[2][ np.random.randint(0, len(samples[2])) ]\n",
        "    r = np.random.randint(1, 3)\n",
        "    x1 = text2ascii_onehot(textSample1)\n",
        "    x2 = text2ascii_onehot(textSample2)\n",
        "    if r == 1:\n",
        "        return x1, x2, np.array([1, 0]), (textSample1, textSample2,)\n",
        "    else:\n",
        "        return x2, x1, np.array([1, 0]), (textSample2, textSample1,)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bVJQT2y6z6W9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, LSTM, Bidirectional, Dot, Concatenate, Subtract, Average\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "import numpy as np\n",
        "\n",
        "text1 = Input(shape=(None, 256))\n",
        "text2 = Input(shape=(None, 256))\n",
        "# concat and return_sequences to retain info\n",
        "shared_blstm1 = Bidirectional( LSTM(units=4, input_shape=(None, 256), return_sequences=True), merge_mode='concat')\n",
        "shared_blstm2 = Bidirectional( LSTM(units=4, input_shape=(None, 256)), merge_mode='concat')\n",
        "transform1 = Dense(128)\n",
        "embedding1 = transform1(shared_blstm2(shared_blstm1(text1)))\n",
        "embedding2 = transform1(shared_blstm2(shared_blstm1(text2)))\n",
        "\n",
        "#sim_layer = Dense(units=8)\n",
        "similarity = Dot(axes=-1, normalize=False)([embedding1, embedding2])\n",
        "softmax_layer = Dense(2, activation='softmax')\n",
        "predict = softmax_layer(similarity)\n",
        "model = Model(inputs=[text1, text2], outputs=predict)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(  )\n",
        "# model.add( Dense(4) )\n",
        "# model.add( Dense(4) )\n",
        "# model.add( Dense(2, activation='softmax') )\n",
        "# model_opt = SGD(lr=0.01, momentum=0.3, decay=0, nesterov=False)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "def get_random_samples(size):\n",
        "    for i in range(size):\n",
        "        r = np.random.randint(1,3)\n",
        "        if r == 1:\n",
        "            return generate_valid()\n",
        "        else:\n",
        "            return generate_invalid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7zEnC5xcYzT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print( model.summary() )\n",
        "\n",
        "for layer in model.layers:\n",
        "    print(\"Input shape: \"+str(layer.input_shape)+\". Output shape: \"+str(layer.output_shape))\n",
        "    \n",
        "for epoch in range(100):\n",
        "    # perform some training\n",
        "    for _ in range(100):\n",
        "        x1, x2, label, data = get_random_samples(1)\n",
        "        x1 = np.array([x1])\n",
        "        x2 = np.array([x2])\n",
        "        label = label.reshape(1, 2)\n",
        "        model.fit([x1,x2], label, verbose=False)\n",
        "    # check results\n",
        "    x1, x2, label, data = get_random_samples(1)\n",
        "    x1 = np.array([x1])\n",
        "    x2 = np.array([x2])\n",
        "    label = label.reshape(1, 2)\n",
        "    r = model.predict([x1,x2])\n",
        "    p1, p2 = np.exp(r[0][0]), np.exp(r[0][1])\n",
        "    p1, p2 = p1/(p1+p2), p2/(p1+p2)\n",
        "    p1 *= 100.0\n",
        "    p2 *= 100.0\n",
        "    \n",
        "    predicted_label = model.predict([x1,x2]).argmax(axis=-1)\n",
        "    print(data, predicted_label, p1 , p2)\n",
        "    print(score)\n",
        "\n",
        "\n",
        "# for i in range(10):\n",
        "#     x, y, samples = get_random_samples(1)\n",
        "#     predicted_label = model.predict(x).argmax(axis=-1)\n",
        "#     print( samples, y, predicted_label )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}